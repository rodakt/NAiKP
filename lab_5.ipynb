{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Metoda gradientu prostego\n",
    "\n",
    "### Tomasz Rodak\n",
    "\n",
    "Laboratorium 5\n",
    "\n",
    "---\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Trening w uczeniu maszynowym\n",
    "\n",
    "Trening (uczenie, optymalizacja) w uczeniu maszynowym to proces, podczas którego model wyznacza swoje parametry w oparciu o dostępne dane. Proces ten może być jednorazowy (gdy istnieje wzór na parametry) lub stopniowy, polegający na iteracyjnym dostosowywaniu parametrów. \n",
    "\n",
    "W przypadku iteracyjnym istotą treningu jest ocena modelu. Do oceny wykorzystuje się funkcję zwaną funkcją **straty** lub **kosztu** pokazującą jak bardzo przewidywania modelu odbiegają od rzeczywistych wartości (kóre w uczeniu nadzorowanym są nam znane). Funkcja ta ma różną postać w zależności od tego z jakim problemem mamy do czynienia:\n",
    "* błąd średniokwadratowy (MSE) w przypadku regresji,\n",
    "* entropia krzyżowa w przypadku klasyfikacji,\n",
    "* funkcja wiarygodności w rożnych modelach probabilistycznych.\n",
    "\n",
    "Trening w postaci iteracyjnej wygląda zwykle następująco:\n",
    "1. inicjalizacja modelu z losowymi parametrami,\n",
    "2. obliczenie wartości funkcji straty na zbiorze testowym,\n",
    "3. sprawdzenie, \n",
    "   * czy parametry modelu przestały się istotnie zmieniać (optymalizacja zbieżna), lub\n",
    "   * czy nie przekroczono limitu iteracji (brak zbieżności).\n",
    "   \n",
    "   Jeśli tak, to proces jest przerywany.\n",
    "4. dostosowanie parametrów,\n",
    "5. powrót do punktu 2.\n",
    "\n",
    "Powstaje pytanie w jaki sposób dostosować parametry modelu w punkcie 4? Funkcja straty może być rozpatrywana jako funkcja przekształcająca parametry modelu w wartość oceny na zbiorze testowym. Zatem poszukiwany jest taki układ parametrów, dla którego funkcja straty obliczana na zbiorze testowym osiąga minimum. Dostosowanie parametrów w punkcie 4 może zatem polegać na podmianie bieżącego układu parametrów na taki układ, który wypada bliżej lokalnego minimum funkcji straty. **Algorytm gradientu prostego** (i wielu jego odmian) opiera się na obserwacji, że kierunek przemieszczania się w przestrzeni parametrów w rejon minimum lokalnego wyznacza ujemny **gradient** funkcji straty.\n",
    "\n",
    "Celem tego arkusza jest wizualna demonstracja działania algorytmu gradientu prostego na prostych przykładach funkcji rzeczywistych. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Algorytm gradientu prostego dla funkcji rzeczywistych jednej zmiennej \n",
    "\n",
    "Załóżmy, że mamy daną funkcję rzeczywistą $y=f(x)$ jednej zmiennej $x$. Chcemy znaleźć jej minimum lokalne. Algorytm gradientu prostego wygląda następująco:\n",
    "\n",
    "1. Ustalamy parametry algorytmu:\n",
    "   * $x_0$ - punkt startowy (dowolny),\n",
    "   * $\\eta>0$ - współczynnik uczenia (dowolny, ale nie za duży),\n",
    "2. Obliczamy kolejne punkty $x_1,x_2,\\ldots$ w następujący sposób:\n",
    "   * $x_{n+1} = x_n - \\eta \\cdot f'(x_n)$, gdzie $f'(x_n)$ to pochodna funkcji $f$ w punkcie $x_n$.\n",
    "3. Proces kończymy, gdy osiągniemy zbieżność, czyli gdy różnice między kolejnymi punktami staną się zaniedbywalnie małe, lub gdy osiągniemy maksymalną liczbę iteracji.\n",
    "4. Zwracamy ostatni punkt $x_n$ jako przybliżenie minimum lokalnego funkcji $f$.\n",
    "\n",
    "Dla funkcji rzeczywistych jednej zmiennej gradient funkcji $f$ w punkcie $x$ to po prostu jej pochodna $f'(x)$. Interpretuje się ją jako nachylenie stycznej do wykresu funkcji w punkcie $x$. Z punktu widzenia poszukiwania minimum lokalnego funkcji $f$ gradient w punkcie $x$ wskazuje kierunek, w którym funkcja $f$ najszybciej rośnie. Kierunek przeciwny, to kierunek, w którym funkcja $f$ najszybciej maleje. Dlatego przemieszczenie się w kierunku przeciwnym do wskazywanego przez gradient powinno prowadzić do (jakiegoś) minimum lokalnego funkcji $f$ i to jest powód, dla którego do bieżącej wartości $x_n$ dodajemy \n",
    "\n",
    "\\begin{equation*}\n",
    "-\\eta \\cdot f'(x_n)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Przykład dla wybranej funkcji\n",
    "\n",
    "Na początek wybierz jakąś prostą dobrze znaną funkcję, np. $f(x) = x^2$. Później możesz ją dowolnie zmieniać. \n",
    "\n",
    "Zdefiniuj swoją funkcję w Pythonie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Narysuj wykres funkcji na jakimś wybranym przedziale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ustal punkt startowy $x_0$ oraz współczynnik uczenia $\\eta>0$. Wykonaj kilka iteracji algorytmu gradientu prostego i narysuj na wykresie funkcji kolejno uzyskiwane punkty $x_n$. Pochodną obliczaj numerycznie stosując wzór:\n",
    "\n",
    "\\begin{equation*}\n",
    "f'(x) \\approx \\frac{f(x+h) - f(x)}{h},\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $h$ to liczba bliska zeru (np. $h=10^{-9}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napisz kod, który automatycznie wykona powyższe kroki.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Wnioski\n",
    "\n",
    "Przeprowadź różne eksperymenty zmieniając funkcję, punkt startowy oraz współczynnik uczenia. Odpowiedz na pytania:\n",
    "\n",
    "1. co się dzieje, gdy współczynnik uczenia jest zbyt duży?\n",
    "2. co się dzieje, gdy współczynnik uczenia jest zbyt mały?\n",
    "3. jak ostateczny wynik algorytmu zależy od wyboru punktu startowego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
